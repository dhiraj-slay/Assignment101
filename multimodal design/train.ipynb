{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-dSLDW3napui",
        "outputId": "4da4fbc7-3ea2-4a6c-f609-0be9274b9308"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ],
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "gfOGOTbqdX_O"
      },
      "outputs": [],
      "source": [
        "'''\n",
        "Training script for ecg classification\n",
        "'''\n",
        "from __future__ import print_function\n",
        "\n",
        "import os\n",
        "import cv2\n",
        "import json\n",
        "import time\n",
        "import torch\n",
        "import random\n",
        "import shutil\n",
        "import argparse\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import torch.nn as nn\n",
        "import torch.nn.parallel\n",
        "import torch.optim as optim\n",
        "import sklearn.metrics as skm\n",
        "import torch.utils.data as data\n",
        "import torch.backends.cudnn as cudnn\n",
        "import matplotlib.pyplot as plt\n",
        "from tqdm import tqdm\n",
        "from sklearn.metrics import roc_curve, auc\n",
        "from matplotlib.backends.backend_agg import FigureCanvasAgg as FigureCanvas\n",
        "from matplotlib.figure import Figure\n",
        "# import models as models\n",
        "from utils import Logger, AverageMeter, mkdir_p, savefig\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "vF7KXC_7hTxx",
        "outputId": "d7a1c3fb-2f50-4b69-d01b-54d024ae5dd5"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "execution_count": 2,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "torch.cuda.is_available()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "id": "NpME8v1Vd3Jx"
      },
      "outputs": [],
      "source": [
        "\n",
        "parser = argparse.ArgumentParser(description='PyTorch ECG LSTM MITBIH Training')\n",
        "# Datasets\n",
        "parser.add_argument('-dt', '--dataset', default='ecg', type=str)\n",
        "parser.add_argument('-ft', '--transformation', default='stft', type=str)\n",
        "parser.add_argument('-d', '--data', default='./generate_features_3/mitbih_rl', type=str)\n",
        "parser.add_argument('-j', '--workers', default=4, type=int, metavar='N',\n",
        "                    help='number of data loading workers (default: 4)')\n",
        "# Optimization options\n",
        "parser.add_argument('--epochs', default=25, type=int, metavar='N',\n",
        "                    help='number of total epochs to run')\n",
        "parser.add_argument('--start-epoch', default=0, type=int, metavar='N',\n",
        "                    help='manual epoch number (useful on restarts)')\n",
        "parser.add_argument('--train-batch', default=8, type=int, metavar='N',\n",
        "                    help='train batchsize')\n",
        "parser.add_argument('--test-batch', default=8, type=int, metavar='N',\n",
        "                    help='test batchsize')\n",
        "parser.add_argument('--lr', '--learning-rate', default=0.001, type=float,\n",
        "                    metavar='LR', help='initial learning rate')\n",
        "parser.add_argument('--drop', '--dropout', default=0, type=float,\n",
        "                    metavar='Dropout', help='Dropout ratio')\n",
        "parser.add_argument('--schedule', type=int, nargs='+', default=[150, 225],\n",
        "                        help='Decrease learning rate at these epochs.')\n",
        "parser.add_argument('--gamma', type=float, default=0.1, help='LR is multiplied by gamma on schedule.')\n",
        "parser.add_argument('--momentum', default=0.9, type=float, metavar='M',\n",
        "                    help='momentum')\n",
        "parser.add_argument('--weight-decay', '--wd', default=5e-4, type=float,\n",
        "                    metavar='W', help='weight decay (default: 1e-4)')\n",
        "# Checkpoints\n",
        "parser.add_argument('-c', '--checkpoint', default='checkpoint', type=str, metavar='PATH',\n",
        "                    help='path to save checkpoint (default: checkpoint)')\n",
        "\n",
        "parser.add_argument('--resume', default='', type=str, metavar='PATH',\n",
        "                    help='path to latest checkpoint (default: none)')\n",
        "\n",
        "# Architecture\n",
        "parser.add_argument('--depth', type=int, default=110, help='Model depth.')\n",
        "parser.add_argument('--block-name', type=str, default='BasicBlock',\n",
        "                    help='the building block for Resnet and Preresnet: BasicBlock, Bottleneck (default: '\n",
        "                         'Basicblock for ecg)')\n",
        "parser.add_argument('--cardinality', type=int, default=8, help='Model cardinality (group).')\n",
        "parser.add_argument('--widen-factor', type=int, default=4, help='Widen factor. 4 -> 64, 8 -> 128, ...')\n",
        "parser.add_argument('--growthRate', type=int, default=12, help='Growth rate for DenseNet.')\n",
        "parser.add_argument('--compressionRate', type=int, default=2, help='Compression Rate (theta) for DenseNet.')\n",
        "# Miscs\n",
        "parser.add_argument('--manualSeed', type=int, help='manual seed')\n",
        "parser.add_argument('-e', '--evaluate', dest='evaluate', action='store_true', default=False,\n",
        "                    help='evaluate model on validation set')\n",
        "# Device options\n",
        "parser.add_argument('--gpu-id', default='0', type=str,\n",
        "                    help='id(s) for CUDA_VISIBLE_DEVICES')\n",
        "\n",
        "args = parser.parse_args(\"\")\n",
        "state = {k: v for k, v in args._get_kwargs()}\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "# Use CUDA\n",
        "os.environ['CUDA_VISIBLE_DEVICES'] = args.gpu_id\n",
        "use_cuda = torch.cuda.is_available()\n",
        "\n",
        "# Random seed\n",
        "if args.manualSeed is None:\n",
        "    args.manualSeed = random.randint(1, 10000)\n",
        "random.seed(args.manualSeed)\n",
        "torch.manual_seed(args.manualSeed)\n",
        "if use_cuda:\n",
        "    torch.cuda.manual_seed_all(args.manualSeed)\n",
        "\n",
        "best_acc = 0  # best test accuracy\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "id": "wZXG1JneeDtx"
      },
      "outputs": [],
      "source": [
        "\n",
        "class Ecg_loader(torch.utils.data.Dataset):\n",
        "    def __init__(self, path, transform):\n",
        "        super(Ecg_loader, self).__init__()\n",
        "        self.male_vec = np.load('male_vec.npy')\n",
        "        self.female_vec = np.load('female_vec.npy')\n",
        "\n",
        "        with open(os.path.join(path, 'ecg_labels.json')) as j_file:\n",
        "            json_data = json.load(j_file)\n",
        "        self.idx2name = json_data['labels']\n",
        "        data = json_data['data']\n",
        "        self.inputs = []\n",
        "        self.labels = []\n",
        "        self.gender = []\n",
        "        self.inputs_full = []\n",
        "        self.whole_ecg = []\n",
        "        self.ecg = []\n",
        "        self.age = []\n",
        "        for i in tqdm(data):\n",
        "            subject_img = []\n",
        "            subject_ecg = []\n",
        "            a = np.zeros((100))\n",
        "            for i_name, w_name in zip(i['images'], i['ecg']):\n",
        "                img = cv2.imread(os.path.join(path, 'images', transform, i_name))\n",
        "                img = cv2.cvtColor(img, cv2.COLOR_BGR2RGB)\n",
        "                img = cv2.resize(img, (90, 90))\n",
        "                ecg = np.load(os.path.join(path, 'ecg', w_name))\n",
        "                subject_img.append(np.expand_dims(img.transpose((2, 0, 1)), axis=0))\n",
        "                subject_ecg.append(np.expand_dims(np.expand_dims(ecg, axis=0), axis=0))\n",
        "            img_full = cv2.imread(os.path.join(path, 'images_full', transform, i['images_full']))\n",
        "            img_full = cv2.cvtColor(img_full, cv2.COLOR_BGR2RGB)\n",
        "            l = i['label']\n",
        "            a[int(i['age']*100)] = 1\n",
        "            if i['gender'] == [0, 1]:\n",
        "                g = self.male_vec\n",
        "            elif i['gender'] == [1, 0]:\n",
        "                g = self.female_vec\n",
        "            self.inputs_full.append(img_full.transpose((2, 0, 1)))\n",
        "            self.inputs.append(np.concatenate(subject_img, axis=0))\n",
        "            self.ecg.append(np.concatenate(subject_ecg, axis=0))\n",
        "            self.whole_ecg.append(np.concatenate(subject_ecg, axis=2))\n",
        "            counts = np.bincount(l)\n",
        "            ind = np.argmax(counts)\n",
        "            encoded_array = np.zeros(6, dtype=np.float64)\n",
        "            encoded_array[ind] = 1.0 \n",
        "            # print(encoded_array)\n",
        "            encoded_array = encoded_array.astype('float64')\n",
        "            self.labels.append(encoded_array)\n",
        "            self.gender.append(g)\n",
        "            self.age.append(a)\n",
        "        print(len(self.whole_ecg))\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.labels)\n",
        "\n",
        "    def __getitem__(self, idx):\n",
        "        x = torch.from_numpy(self.inputs[idx]).float()\n",
        "        # y = torch.from_numpy(np.array(self.labels[idx])).long()\n",
        "        y = torch.from_numpy(np.array(self.labels[idx]))\n",
        "        a = torch.from_numpy(np.array(self.age[idx])).float()\n",
        "        g = torch.from_numpy(np.array(self.gender[idx])).float()\n",
        "        w = torch.from_numpy(self.ecg[idx]).float()\n",
        "        return (x, a, g, w), y"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "n61AGj5HeMIx",
        "outputId": "9c4800f2-687c-4810-c2f5-89d21e2ee7fc"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "==> Preparing dataset ecg\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 1782/1782 [00:26<00:00, 66.72it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "1782\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 198/198 [00:05<00:00, 39.46it/s]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "198\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\n",
            "/usr/local/lib/python3.8/dist-packages/torch/utils/data/dataloader.py:554: UserWarning: This DataLoader will create 4 worker processes in total. Our suggested max number of worker in current system is 2, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
            "  warnings.warn(_create_warning_msg(\n"
          ]
        }
      ],
      "source": [
        "\n",
        "start_epoch = args.start_epoch  # start from epoch 0 or last checkpoint epoch\n",
        "\n",
        "if not os.path.isdir(args.checkpoint):\n",
        "    mkdir_p(args.checkpoint)\n",
        "\n",
        "# Data\n",
        "print('==> Preparing dataset %s' % args.dataset)\n",
        "\n",
        "dataloader = Ecg_loader\n",
        "train_path = args.data\n",
        "\n",
        "traindir = os.path.join(train_path, 'train')\n",
        "valdir = os.path.join(train_path, 'val')\n",
        "if not args.evaluate:\n",
        "    trainset = dataloader(traindir, transform=args.transformation)\n",
        "testset = dataloader(valdir, transform=args.transformation)\n",
        "\n",
        "idx2name = testset.idx2name\n",
        "label_names = []\n",
        "for i in range(0, len(idx2name.keys())):\n",
        "    label_names.append(idx2name[str(i)])\n",
        "num_classes = len(label_names)\n",
        "\n",
        "if not args.evaluate:\n",
        "    trainloader = data.DataLoader(trainset, batch_size=args.train_batch, shuffle=True, num_workers=args.workers)\n",
        "testloader = data.DataLoader(testset, batch_size=args.test_batch, shuffle=False, num_workers=args.workers)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "id": "m24a1f5qB4T5"
      },
      "outputs": [],
      "source": [
        "from collections import defaultdict\n",
        "import csv\n",
        "import json\n",
        "import numpy as np\n",
        "import os\n",
        "import sys\n",
        "\n",
        "from sklearn.metrics import roc_curve, auc\n",
        "from tqdm import tqdm\n",
        "\n",
        "\n",
        "\n",
        "def all_metrics(yhat, y, k=8, yhat_raw=None, calc_auc=True):\n",
        "    \"\"\"\n",
        "        Inputs:\n",
        "            yhat: binary predictions matrix \n",
        "            y: binary ground truth matrix\n",
        "            k: for @k metrics\n",
        "            yhat_raw: prediction scores matrix (floats)\n",
        "        Outputs:\n",
        "            dict holding relevant metrics\n",
        "    \"\"\"\n",
        "    names = [\"acc\", \"prec\", \"rec\", \"f1\"]\n",
        "\n",
        "    #macro\n",
        "    macro = all_macro(yhat, y)\n",
        "\n",
        "    #micro\n",
        "    ymic = y.ravel()\n",
        "    yhatmic = yhat.ravel()\n",
        "    micro = all_micro(yhatmic, ymic)\n",
        "\n",
        "    metrics = {names[i] + \"_macro\": macro[i] for i in range(len(macro))}\n",
        "    metrics.update({names[i] + \"_micro\": micro[i] for i in range(len(micro))})\n",
        "\n",
        "    #AUC and @k\n",
        "    if yhat_raw is not None and calc_auc:\n",
        "        #allow k to be passed as int or list\n",
        "        if type(k) != list:\n",
        "            k = [k]\n",
        "        for k_i in k:\n",
        "            rec_at_k = recall_at_k(yhat_raw, y, k_i)\n",
        "            metrics['rec_at_%d' % k_i] = rec_at_k\n",
        "            prec_at_k = precision_at_k(yhat_raw, y, k_i)\n",
        "            metrics['prec_at_%d' % k_i] = prec_at_k\n",
        "            metrics['f1_at_%d' % k_i] = 2*(prec_at_k*rec_at_k)/(prec_at_k+rec_at_k)\n",
        "\n",
        "        roc_auc = auc_metrics(yhat_raw, y, ymic)\n",
        "        metrics.update(roc_auc)\n",
        "\n",
        "    return metrics\n",
        "\n",
        "def all_macro(yhat, y):\n",
        "    return macro_accuracy(yhat, y), macro_precision(yhat, y), macro_recall(yhat, y), macro_f1(yhat, y)\n",
        "\n",
        "def all_micro(yhatmic, ymic):\n",
        "    return micro_accuracy(yhatmic, ymic), micro_precision(yhatmic, ymic), micro_recall(yhatmic, ymic), micro_f1(yhatmic, ymic)\n",
        "\n",
        "#########################################################################\n",
        "#MACRO METRICS: calculate metric for each label and average across labels\n",
        "#########################################################################\n",
        "\n",
        "def macro_accuracy(yhat, y):\n",
        "    num = intersect_size(yhat, y, 0) / (union_size(yhat, y, 0) + 1e-10)\n",
        "    return np.mean(num)\n",
        "\n",
        "def macro_precision(yhat, y):\n",
        "    num = intersect_size(yhat, y, 0) / (yhat.sum(axis=0) + 1e-10)\n",
        "    return np.mean(num)\n",
        "\n",
        "def macro_recall(yhat, y):\n",
        "    num = intersect_size(yhat, y, 0) / (y.sum(axis=0) + 1e-10)\n",
        "    return np.mean(num)\n",
        "\n",
        "def macro_f1(yhat, y):\n",
        "    prec = macro_precision(yhat, y)\n",
        "    rec = macro_recall(yhat, y)\n",
        "    if prec + rec == 0:\n",
        "        f1 = 0.\n",
        "    else:\n",
        "        f1 = 2*(prec*rec)/(prec+rec)\n",
        "    return f1\n",
        "\n",
        "###################\n",
        "# INSTANCE-AVERAGED\n",
        "###################\n",
        "\n",
        "def inst_precision(yhat, y):\n",
        "    num = intersect_size(yhat, y, 1) / yhat.sum(axis=1)\n",
        "    #correct for divide-by-zeros\n",
        "    num[np.isnan(num)] = 0.\n",
        "    return np.mean(num)\n",
        "\n",
        "def inst_recall(yhat, y):\n",
        "    num = intersect_size(yhat, y, 1) / y.sum(axis=1)\n",
        "    #correct for divide-by-zeros\n",
        "    num[np.isnan(num)] = 0.\n",
        "    return np.mean(num)\n",
        "\n",
        "def inst_f1(yhat, y):\n",
        "    prec = inst_precision(yhat, y)\n",
        "    rec = inst_recall(yhat, y)\n",
        "    f1 = 2*(prec*rec)/(prec+rec)\n",
        "    return f1\n",
        "\n",
        "##############\n",
        "# AT-K\n",
        "##############\n",
        "\n",
        "def recall_at_k(yhat_raw, y, k):\n",
        "    #num true labels in top k predictions / num true labels\n",
        "    sortd = np.argsort(yhat_raw)[:,::-1]\n",
        "    topk = sortd[:,:k]\n",
        "\n",
        "    #get recall at k for each example\n",
        "    vals = []\n",
        "    for i, tk in enumerate(topk):\n",
        "        num_true_in_top_k = y[i,tk].sum()\n",
        "        denom = y[i,:].sum()\n",
        "        vals.append(num_true_in_top_k / float(denom))\n",
        "\n",
        "    vals = np.array(vals)\n",
        "    vals[np.isnan(vals)] = 0.\n",
        "\n",
        "    return np.mean(vals)\n",
        "\n",
        "def precision_at_k(yhat_raw, y, k):\n",
        "    #num true labels in top k predictions / k\n",
        "    sortd = np.argsort(yhat_raw)[:,::-1]\n",
        "    topk = sortd[:,:k]\n",
        "\n",
        "    #get precision at k for each example\n",
        "    vals = []\n",
        "    for i, tk in enumerate(topk):\n",
        "        if len(tk) > 0:\n",
        "            num_true_in_top_k = y[i,tk].sum()\n",
        "            denom = len(tk)\n",
        "            vals.append(num_true_in_top_k / float(denom))\n",
        "\n",
        "    return np.mean(vals)\n",
        "\n",
        "##########################################################################\n",
        "#MICRO METRICS: treat every prediction as an individual binary prediction\n",
        "##########################################################################\n",
        "\n",
        "def micro_accuracy(yhatmic, ymic):\n",
        "    return intersect_size(yhatmic, ymic, 0) / union_size(yhatmic, ymic, 0)\n",
        "\n",
        "def micro_precision(yhatmic, ymic):\n",
        "    return intersect_size(yhatmic, ymic, 0) / yhatmic.sum(axis=0)\n",
        "\n",
        "def micro_recall(yhatmic, ymic):\n",
        "    return intersect_size(yhatmic, ymic, 0) / ymic.sum(axis=0)\n",
        "\n",
        "def micro_f1(yhatmic, ymic):\n",
        "    prec = micro_precision(yhatmic, ymic)\n",
        "    rec = micro_recall(yhatmic, ymic)\n",
        "    if prec + rec == 0:\n",
        "        f1 = 0.\n",
        "    else:\n",
        "        f1 = 2*(prec*rec)/(prec+rec)\n",
        "    return f1\n",
        "\n",
        "def auc_metrics(yhat_raw, y, ymic):\n",
        "    if yhat_raw.shape[0] <= 1:\n",
        "        return\n",
        "    fpr = {}\n",
        "    tpr = {}\n",
        "    roc_auc = {}\n",
        "    #get AUC for each label individually\n",
        "    relevant_labels = []\n",
        "    auc_labels = {}\n",
        "    for i in range(y.shape[1]):\n",
        "        #only if there are true positives for this label\n",
        "        if y[:,i].sum() > 0:\n",
        "            fpr[i], tpr[i], _ = roc_curve(y[:,i], yhat_raw[:,i])\n",
        "            if len(fpr[i]) > 1 and len(tpr[i]) > 1:\n",
        "                auc_score = auc(fpr[i], tpr[i])\n",
        "                if not np.isnan(auc_score): \n",
        "                    auc_labels[\"auc_%d\" % i] = auc_score\n",
        "                    relevant_labels.append(i)\n",
        "\n",
        "    #macro-AUC: just average the auc scores\n",
        "    aucs = []\n",
        "    for i in relevant_labels:\n",
        "        aucs.append(auc_labels['auc_%d' % i])\n",
        "    roc_auc['auc_macro'] = np.mean(aucs)\n",
        "\n",
        "    #micro-AUC: just look at each individual prediction\n",
        "    yhatmic = yhat_raw.ravel()\n",
        "    fpr[\"micro\"], tpr[\"micro\"], _ = roc_curve(ymic, yhatmic) \n",
        "    roc_auc[\"auc_micro\"] = auc(fpr[\"micro\"], tpr[\"micro\"])\n",
        "\n",
        "    return roc_auc\n",
        "\n",
        "########################\n",
        "# METRICS BY CODE TYPE\n",
        "########################\n",
        "\n",
        "def results_by_type(Y, mdir, version='mimic3'):\n",
        "    d2ind = {}\n",
        "    p2ind = {}\n",
        "\n",
        "    #get predictions for diagnoses and procedures\n",
        "    diag_preds = defaultdict(lambda: set([]))\n",
        "    proc_preds = defaultdict(lambda: set([]))\n",
        "    preds = defaultdict(lambda: set())\n",
        "    with open('%s/preds_test.psv' % mdir, 'r') as f:\n",
        "        r = csv.reader(f, delimiter='|')\n",
        "        for row in r:\n",
        "            if len(row) > 1:\n",
        "                for code in row[1:]:\n",
        "                    preds[row[0]].add(code)\n",
        "                    if code != '':\n",
        "                        try:\n",
        "                            pos = code.index('.')\n",
        "                            if pos == 3 or (code[0] == 'E' and pos == 4):\n",
        "                                if code not in d2ind:\n",
        "                                    d2ind[code] = len(d2ind)\n",
        "                                diag_preds[row[0]].add(code)\n",
        "                            elif pos == 2:\n",
        "                                if code not in p2ind:\n",
        "                                    p2ind[code] = len(p2ind)\n",
        "                                proc_preds[row[0]].add(code)\n",
        "                        except:\n",
        "                            if len(code) == 3 or (code[0] == 'E' and len(code) == 4):\n",
        "                                if code not in d2ind:\n",
        "                                    d2ind[code] = len(d2ind)\n",
        "                                diag_preds[row[0]].add(code)\n",
        "    #get ground truth for diagnoses and procedures\n",
        "    diag_golds = defaultdict(lambda: set([]))\n",
        "    proc_golds = defaultdict(lambda: set([]))\n",
        "    golds = defaultdict(lambda: set())\n",
        "    test_file = '%s/test_%s.csv' % (MIMIC_3_DIR, str(Y)) if version == 'mimic3' else '%s/test.csv' % MIMIC_2_DIR\n",
        "    with open(test_file, 'r') as f:\n",
        "        r = csv.reader(f)\n",
        "        #header\n",
        "        next(r)\n",
        "        for row in r:\n",
        "            codes = set([c for c in row[3].split(';')])\n",
        "            for code in codes:\n",
        "                golds[row[1]].add(code)\n",
        "                try:\n",
        "                    pos = code.index('.')\n",
        "                    if pos == 3:\n",
        "                        if code not in d2ind:\n",
        "                            d2ind[code] = len(d2ind)\n",
        "                        diag_golds[row[1]].add(code)\n",
        "                    elif pos == 2:\n",
        "                        if code not in p2ind:\n",
        "                            p2ind[code] = len(p2ind)\n",
        "                        proc_golds[row[1]].add(code)\n",
        "                except:\n",
        "                    if len(code) == 3 or (code[0] == 'E' and len(code) == 4):\n",
        "                        if code not in d2ind:\n",
        "                            d2ind[code] = len(d2ind)\n",
        "                        diag_golds[row[1]].add(code)\n",
        "\n",
        "    hadm_ids = sorted(set(diag_golds.keys()).intersection(set(diag_preds.keys())))\n",
        "\n",
        "    ind2d = {i:d for d,i in d2ind.items()}\n",
        "    ind2p = {i:p for p,i in p2ind.items()}\n",
        "    type_dicts = (ind2d, ind2p)\n",
        "    return diag_preds, diag_golds, proc_preds, proc_golds, golds, preds, hadm_ids, type_dicts\n",
        "\n",
        "\n",
        "def diag_f1(diag_preds, diag_golds, ind2d, hadm_ids):\n",
        "    num_labels = len(ind2d)\n",
        "    yhat_diag = np.zeros((len(hadm_ids), num_labels))\n",
        "    y_diag = np.zeros((len(hadm_ids), num_labels))\n",
        "    for i,hadm_id in tqdm(enumerate(hadm_ids)):\n",
        "        yhat_diag_inds = [1 if ind2d[j] in diag_preds[hadm_id] else 0 for j in range(num_labels)]\n",
        "        gold_diag_inds = [1 if ind2d[j] in diag_golds[hadm_id] else 0 for j in range(num_labels)]\n",
        "        yhat_diag[i] = yhat_diag_inds\n",
        "        y_diag[i] = gold_diag_inds\n",
        "    return micro_f1(yhat_diag.ravel(), y_diag.ravel())\n",
        "\n",
        "def proc_f1(proc_preds, proc_golds, ind2p, hadm_ids):\n",
        "    num_labels = len(ind2p)\n",
        "    yhat_proc = np.zeros((len(hadm_ids), num_labels))\n",
        "    y_proc = np.zeros((len(hadm_ids), num_labels))\n",
        "    for i,hadm_id in tqdm(enumerate(hadm_ids)):\n",
        "        yhat_proc_inds = [1 if ind2p[j] in proc_preds[hadm_id] else 0 for j in range(num_labels)]\n",
        "        gold_proc_inds = [1 if ind2p[j] in proc_golds[hadm_id] else 0 for j in range(num_labels)]\n",
        "        yhat_proc[i] = yhat_proc_inds\n",
        "        y_proc[i] = gold_proc_inds\n",
        "    return micro_f1(yhat_proc.ravel(), y_proc.ravel())\n",
        "\n",
        "def metrics_from_dicts(preds, golds, mdir, ind2c):\n",
        "    with open('%s/pred_100_scores_test.json' % mdir, 'r') as f:\n",
        "        scors = json.load(f)\n",
        "\n",
        "    hadm_ids = sorted(set(golds.keys()).intersection(set(preds.keys())))\n",
        "    num_labels = len(ind2c)\n",
        "    yhat = np.zeros((len(hadm_ids), num_labels))\n",
        "    yhat_raw = np.zeros((len(hadm_ids), num_labels))\n",
        "    y = np.zeros((len(hadm_ids), num_labels))\n",
        "    for i,hadm_id in tqdm(enumerate(hadm_ids)):\n",
        "        yhat_inds = [1 if ind2c[j] in preds[hadm_id] else 0 for j in range(num_labels)]\n",
        "        yhat_raw_inds = [scors[hadm_id][ind2c[j]] if ind2c[j] in scors[hadm_id] else 0 for j in range(num_labels)]\n",
        "        gold_inds = [1 if ind2c[j] in golds[hadm_id] else 0 for j in range(num_labels)]\n",
        "        yhat[i] = yhat_inds\n",
        "        yhat_raw[i] = yhat_raw_inds\n",
        "        y[i] = gold_inds\n",
        "    return yhat, yhat_raw, y, all_metrics(yhat, y, yhat_raw=yhat_raw, calc_auc=False)\n",
        "\n",
        "\n",
        "def union_size(yhat, y, axis):\n",
        "    #axis=0 for label-level union (macro). axis=1 for instance-level\n",
        "    return np.logical_or(yhat, y).sum(axis=axis).astype(float)\n",
        "\n",
        "def intersect_size(yhat, y, axis):\n",
        "    #axis=0 for label-level union (macro). axis=1 for instance-level\n",
        "    return np.logical_and(yhat, y).sum(axis=axis).astype(float)\n",
        "\n",
        "def print_metrics(metrics):\n",
        "    print()\n",
        "    if \"auc_macro\" in metrics.keys():\n",
        "        print(\"[MACRO] accuracy, precision, recall, f-measure, AUC\")\n",
        "        print(\"%.4f, %.4f, %.4f, %.4f, %.4f\" % (metrics[\"acc_macro\"], metrics[\"prec_macro\"], metrics[\"rec_macro\"], metrics[\"f1_macro\"], metrics[\"auc_macro\"]))\n",
        "    else:\n",
        "        print(\"[MACRO] accuracy, precision, recall, f-measure\")\n",
        "        print(\"%.4f, %.4f, %.4f, %.4f\" % (metrics[\"acc_macro\"], metrics[\"prec_macro\"], metrics[\"rec_macro\"], metrics[\"f1_macro\"]))\n",
        "\n",
        "    if \"auc_micro\" in metrics.keys():\n",
        "        print(\"[MICRO] accuracy, precision, recall, f-measure, AUC\")\n",
        "        print(\"%.4f, %.4f, %.4f, %.4f, %.4f\" % (metrics[\"acc_micro\"], metrics[\"prec_micro\"], metrics[\"rec_micro\"], metrics[\"f1_micro\"], metrics[\"auc_micro\"]))\n",
        "    else:\n",
        "        print(\"[MICRO] accuracy, precision, recall, f-measure\")\n",
        "        print(\"%.4f, %.4f, %.4f, %.4f\" % (metrics[\"acc_micro\"], metrics[\"prec_micro\"], metrics[\"rec_micro\"], metrics[\"f1_micro\"]))\n",
        "    for metric, val in metrics.items():\n",
        "        if metric.find(\"rec_at\") != -1:\n",
        "            print(\"%s: %.4f\" % (metric, val))\n",
        "    print()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 27,
      "metadata": {
        "id": "jBqR11GHFanZ"
      },
      "outputs": [],
      "source": [
        "\n",
        "\n",
        "# def evaluate(outputs, labels, label_names=None):\n",
        "#     gt = torch.cat(labels, dim=0)\n",
        "#     pred = torch.cat(outputs, dim=0)\n",
        "#     probs = pred\n",
        "#     pred = torch.argmax(pred, dim=1)\n",
        "#     acc = torch.div(100*torch.sum((gt == pred).float()), gt.shape[0])\n",
        "#     name_dict = {0: 'Normal beat (N)', 1: 'Left bundle branch block beat (L)', 2: 'Right bundle branch block beat (R)', 3:\n",
        "#         'Premature ventricular contraction (V)', 4: 'Atrial premature beat (A)', 5: 'Non classified (~)'}\n",
        "\n",
        "#     print('accuracy :', acc)\n",
        "\n",
        "#     gt = gt.cpu().tolist()\n",
        "#     pred = pred.cpu().tolist()\n",
        "\n",
        "#     report = skm.classification_report(\n",
        "#         gt, pred,\n",
        "#         target_names=[name_dict[i] for i in np.unique(gt)],\n",
        "#         digits=3)\n",
        "#     scores = skm.precision_recall_fscore_support(\n",
        "#         gt,\n",
        "#         pred,\n",
        "#         average=None)\n",
        "#     print(report)\n",
        "#     print(\"F1 Average {:3f}\".format(np.mean(scores[2][:3])))\n",
        "\n",
        "#     fpr = dict()\n",
        "#     tpr = dict()\n",
        "#     roc_auc = dict()\n",
        "#     n_classes = np.unique(gt).shape[0]\n",
        "#     oh_gt = np.zeros((len(gt), n_classes))\n",
        "#     plt.figure()\n",
        "#     colors = ['b', 'g', 'r', 'c', 'm', 'y']\n",
        "\n",
        "#     for i in range(n_classes):\n",
        "#         oh_gt[:, gt == i] = 1\n",
        "#         fpr[i], tpr[i], _ = roc_curve(gt, probs[:, i].cpu(), pos_label=i)\n",
        "#         roc_auc[i] = auc(fpr[i], tpr[i])\n",
        "#         lw = 2\n",
        "#         plt.plot(fpr[i], tpr[i], color=colors[i],\n",
        "#                  lw=lw, label=name_dict[i] +' : %0.4f' % roc_auc[i])\n",
        "#     plt.xlim([0.0, 1.0])\n",
        "#     plt.ylim([0.0, 1.05])\n",
        "#     plt.xlabel('False Positive Rate')\n",
        "#     plt.ylabel('True Positive Rate')\n",
        "#     plt.title('Class-Wise AUC and ROC curve')\n",
        "#     plt.legend(loc=\"lower right\")\n",
        "#     plt.savefig(os.path.join(args.checkpoint, 'roc.png'))\n",
        "#     return 0\n",
        "\n",
        "\n",
        "\n",
        "def train(trainloader, model, criterion, optimizer, epoch, use_cuda):\n",
        "    # switch to train mode\n",
        "    model.train()\n",
        "\n",
        "    batch_time = AverageMeter()\n",
        "    data_time = AverageMeter()\n",
        "    losses = AverageMeter()\n",
        "    top1 = AverageMeter()\n",
        "    top5 = AverageMeter()\n",
        "    end = time.time()\n",
        "\n",
        "\n",
        "    for batch_idx, (inputs, targets) in tqdm(enumerate(trainloader)):\n",
        "        # measure data loading time\n",
        "        data_time.update(time.time() - end)\n",
        "\n",
        "        if use_cuda:\n",
        "            inputs, targets = (inputs[0].cuda(), inputs[1].cuda(), inputs[2].cuda(),\n",
        "                               inputs[3].cuda()), targets.cuda()\n",
        "        inputs, targets = (torch.autograd.Variable(inputs[0]), torch.autograd.Variable(inputs[1]),\n",
        "                           torch.autograd.Variable(inputs[2]),\n",
        "                           torch.autograd.Variable(inputs[3])), torch.autograd.Variable(targets)\n",
        "        optimizer.zero_grad()\n",
        "        outputs = model(inputs)\n",
        "        # print(outputs)\n",
        "        # print(inputs)\n",
        "        # print(\"*******************\")\n",
        "        # print(outputs.size() , targets.size())\n",
        "        loss = criterion(outputs, targets)\n",
        "\n",
        "        # print(outputs.size(), targets.size())\n",
        "        # print(outputs, targets)\n",
        "        # prec1, prec5 = accuracy(outputs.data, targets.data, topk=(1, 6))\n",
        "        output_np = outputs.data.cpu().numpy()\n",
        "        output_np = np.nan_to_num(output_np)\n",
        "        yhat =  (output_np > 0.5)\n",
        "        met = all_metrics(yhat, targets.data.cpu().numpy(), k=3, yhat_raw=output_np, calc_auc=True)\n",
        "        if float(torch.__version__[:3]) < 0.5:\n",
        "            losses.update(loss.data[0], inputs[0].size(0))\n",
        "            # top1.update(prec1[0], inputs[0].size(0))\n",
        "            # top5.update(prec5[0], inputs[0].size(0))\n",
        "        else:\n",
        "            losses.update(loss.data, inputs[0].size(0))\n",
        "            # top1.update(prec1, inputs[0].size(0))\n",
        "            # top5.update(prec5, inputs[0].size(0))\n",
        "\n",
        "        # compute gradient and do Adam step\n",
        "        \n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "\n",
        "        # measure elapsed time\n",
        "        batch_time.update(time.time() - end)\n",
        "        end = time.time()\n",
        "    # evaluate(pred, gt)\n",
        "    return losses.avg,  met\n",
        "\n",
        "\n",
        "def test(testloader, model, criterion, epoch, use_cuda, label_names=None):\n",
        "    global best_acc\n",
        "\n",
        "    batch_time = AverageMeter()\n",
        "    data_time = AverageMeter()\n",
        "    losses = AverageMeter()\n",
        "    top1 = AverageMeter()\n",
        "    top5 = AverageMeter()\n",
        "\n",
        "    # switch to evaluate mode\n",
        "    model.eval()\n",
        "\n",
        "    end = time.time()\n",
        "\n",
        "    all_preds = []\n",
        "    all_preds_raw = []\n",
        "    all_labels = []\n",
        "    for batch_idx, (inputs, targets) in tqdm(enumerate(testloader)):\n",
        "        # measure data loading time\n",
        "        data_time.update(time.time() - end)\n",
        "\n",
        "        if use_cuda:\n",
        "            inputs, targets = (inputs[0].cuda(), inputs[1].cuda(), inputs[2].cuda(),\n",
        "                               inputs[3].cuda()), targets.cuda()\n",
        "        inputs, targets = (torch.autograd.Variable(inputs[0]), torch.autograd.Variable(inputs[1]),\n",
        "                           torch.autograd.Variable(inputs[2]),\n",
        "                           torch.autograd.Variable(inputs[3])), torch.autograd.Variable(targets)\n",
        "\n",
        "        # compute output\n",
        "        st = time.time()\n",
        "        # print(inputs.shape())\n",
        "        with torch.no_grad():\n",
        "          outputs = model(inputs)\n",
        "        # print(time.time()-st)\n",
        "        loss = criterion(outputs, targets)\n",
        "        targets = targets.data.cpu().numpy()\n",
        "        outputs = outputs.data.cpu().numpy()\n",
        "        output_np = np.nan_to_num(outputs)\n",
        "        yhat =  (output_np > 0.5)\n",
        "        \n",
        "        # measure accuracy and record loss\n",
        "        \n",
        "        # gt.append(targets.tolist())\n",
        "        # pred.append(output_np.tolist())\n",
        "        all_preds_raw.extend(list(output_np))\n",
        "        all_preds.extend(list(yhat))\n",
        "        all_labels.extend(list(targets))\n",
        "        # print(len(all_preds_raw))\n",
        "        # print(pred.shape)\n",
        "        # print(y_hat.shape)\n",
        "\n",
        "        # prec1, prec5 = accuracy(outputs.data, targets.data, topk=(1, 6))\n",
        "        if float(torch.__version__[:3]) < 0.5:\n",
        "            losses.update(loss.data[0], inputs[0].size(0))\n",
        "            # top1.update(prec1[0], inputs[0].size(0))\n",
        "            # top5.update(prec5[0], inputs[0].size(0))\n",
        "        else:\n",
        "            losses.update(loss.data, inputs[0].size(0))\n",
        "            # top1.update(prec1, inputs[0].size(0))\n",
        "            # top5.update(prec5, inputs[0].size(0))\n",
        "\n",
        "        # measure elapsed time\n",
        "        batch_time.update(time.time() - end)\n",
        "        end = time.time()\n",
        "    # print(pred)\n",
        "    # gt_array = np.array(gt)\n",
        "    # pred_array = np.array(pred)\n",
        "    # print(pred_array.shape)\n",
        "    \n",
        "    # yhat =  (pred_array > 0.5)\n",
        "    all_preds_raw = np.stack(all_preds_raw)\n",
        "    all_preds = np.stack(all_preds)\n",
        "    all_labels = np.stack(all_labels)\n",
        "    met = all_metrics(yhat=all_preds, y=all_labels, k = 3,  yhat_raw=all_preds_raw)\n",
        "    # met = all_metrics(y_hat, gt, k=3, yhat_raw=pred, calc_auc=True)\n",
        "    # evaluate(pred, gt, label_names=label_names)\n",
        "    return losses.avg, met\n",
        "\n",
        "\n",
        "def save_checkpoint(state, is_best, checkpoint='checkpoint', filename='checkpoint.pth.tar'):\n",
        "    filepath = os.path.join(checkpoint, filename)\n",
        "    torch.save(state, filepath)\n",
        "    if is_best:\n",
        "        shutil.copyfile(filepath, os.path.join(checkpoint, 'model_best.pth.tar'))\n",
        "\n",
        "\n",
        "def adjust_learning_rate(optimizer, epoch):\n",
        "    global state\n",
        "    if epoch in args.schedule:\n",
        "        state['lr'] *= args.gamma\n",
        "        for param_group in optimizer.param_groups:\n",
        "            param_group['lr'] = state['lr']\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "l46XBLyce5yf",
        "outputId": "da71faa5-9061-49df-c472-587464b25023"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "==> creating model ResNet110\n",
            "    Total params: 4.10M\n",
            "\n",
            "Epoch: [1 | 25] LR: 0.001000\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "223it [02:34,  1.45it/s]\n",
            "25it [00:04,  5.66it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Train accuracy  {'acc_macro': 0.0, 'prec_macro': 0.0, 'rec_macro': 0.0, 'f1_macro': 0.0, 'acc_micro': 0.0, 'prec_micro': nan, 'rec_micro': 0.0, 'f1_micro': nan, 'rec_at_3': 0.16666666666666666, 'prec_at_3': 0.05555555555555555, 'f1_at_3': 0.08333333333333333, 'auc_macro': 0.5, 'auc_micro': 0.5}\n",
            "test accuracy  {'acc_macro': 0.0, 'prec_macro': 0.0, 'rec_macro': 0.0, 'f1_macro': 0.0, 'acc_micro': 0.0, 'prec_micro': nan, 'rec_micro': 0.0, 'f1_micro': nan, 'rec_at_3': 0.2727272727272727, 'prec_at_3': 0.09090909090909091, 'f1_at_3': 0.13636363636363635, 'auc_macro': 0.5, 'auc_micro': 0.5}\n",
            "\n",
            "Epoch: [2 | 25] LR: 0.001000\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "223it [02:36,  1.42it/s]\n",
            "25it [00:04,  5.58it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Train accuracy  {'acc_macro': 0.0, 'prec_macro': 0.0, 'rec_macro': 0.0, 'f1_macro': 0.0, 'acc_micro': 0.0, 'prec_micro': nan, 'rec_micro': 0.0, 'f1_micro': nan, 'rec_at_3': 0.16666666666666666, 'prec_at_3': 0.05555555555555555, 'f1_at_3': 0.08333333333333333, 'auc_macro': 0.5, 'auc_micro': 0.5}\n",
            "test accuracy  {'acc_macro': 0.0, 'prec_macro': 0.0, 'rec_macro': 0.0, 'f1_macro': 0.0, 'acc_micro': 0.0, 'prec_micro': nan, 'rec_micro': 0.0, 'f1_micro': nan, 'rec_at_3': 0.2727272727272727, 'prec_at_3': 0.09090909090909091, 'f1_at_3': 0.13636363636363635, 'auc_macro': 0.5, 'auc_micro': 0.5}\n",
            "\n",
            "Epoch: [3 | 25] LR: 0.001000\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "223it [02:37,  1.42it/s]\n",
            "25it [00:04,  5.42it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Train accuracy  {'acc_macro': 0.0, 'prec_macro': 0.0, 'rec_macro': 0.0, 'f1_macro': 0.0, 'acc_micro': 0.0, 'prec_micro': nan, 'rec_micro': 0.0, 'f1_micro': nan, 'rec_at_3': 0.5, 'prec_at_3': 0.16666666666666666, 'f1_at_3': 0.25, 'auc_macro': 0.5, 'auc_micro': 0.5}\n",
            "test accuracy  {'acc_macro': 0.0, 'prec_macro': 0.0, 'rec_macro': 0.0, 'f1_macro': 0.0, 'acc_micro': 0.0, 'prec_micro': nan, 'rec_micro': 0.0, 'f1_micro': nan, 'rec_at_3': 0.2727272727272727, 'prec_at_3': 0.09090909090909091, 'f1_at_3': 0.13636363636363635, 'auc_macro': 0.5, 'auc_micro': 0.5}\n",
            "\n",
            "Epoch: [4 | 25] LR: 0.001000\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "223it [02:37,  1.42it/s]\n",
            "25it [00:04,  5.43it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Train accuracy  {'acc_macro': 0.0, 'prec_macro': 0.0, 'rec_macro': 0.0, 'f1_macro': 0.0, 'acc_micro': 0.0, 'prec_micro': nan, 'rec_micro': 0.0, 'f1_micro': nan, 'rec_at_3': 0.0, 'prec_at_3': 0.0, 'f1_at_3': nan, 'auc_macro': 0.5, 'auc_micro': 0.5}\n",
            "test accuracy  {'acc_macro': 0.0, 'prec_macro': 0.0, 'rec_macro': 0.0, 'f1_macro': 0.0, 'acc_micro': 0.0, 'prec_micro': nan, 'rec_micro': 0.0, 'f1_micro': nan, 'rec_at_3': 0.2727272727272727, 'prec_at_3': 0.09090909090909091, 'f1_at_3': 0.13636363636363635, 'auc_macro': 0.5, 'auc_micro': 0.5}\n",
            "\n",
            "Epoch: [5 | 25] LR: 0.001000\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "223it [02:37,  1.41it/s]\n",
            "25it [00:04,  5.57it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Train accuracy  {'acc_macro': 0.0, 'prec_macro': 0.0, 'rec_macro': 0.0, 'f1_macro': 0.0, 'acc_micro': 0.0, 'prec_micro': nan, 'rec_micro': 0.0, 'f1_micro': nan, 'rec_at_3': 0.16666666666666666, 'prec_at_3': 0.05555555555555555, 'f1_at_3': 0.08333333333333333, 'auc_macro': 0.5, 'auc_micro': 0.5}\n",
            "test accuracy  {'acc_macro': 0.0, 'prec_macro': 0.0, 'rec_macro': 0.0, 'f1_macro': 0.0, 'acc_micro': 0.0, 'prec_micro': nan, 'rec_micro': 0.0, 'f1_micro': nan, 'rec_at_3': 0.2727272727272727, 'prec_at_3': 0.09090909090909091, 'f1_at_3': 0.13636363636363635, 'auc_macro': 0.5, 'auc_micro': 0.5}\n",
            "\n",
            "Epoch: [6 | 25] LR: 0.001000\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "223it [02:37,  1.42it/s]\n",
            "25it [00:04,  5.64it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Train accuracy  {'acc_macro': 0.0, 'prec_macro': 0.0, 'rec_macro': 0.0, 'f1_macro': 0.0, 'acc_micro': 0.0, 'prec_micro': nan, 'rec_micro': 0.0, 'f1_micro': nan, 'rec_at_3': 0.0, 'prec_at_3': 0.0, 'f1_at_3': nan, 'auc_macro': nan, 'auc_micro': 0.5}\n",
            "test accuracy  {'acc_macro': 0.0, 'prec_macro': 0.0, 'rec_macro': 0.0, 'f1_macro': 0.0, 'acc_micro': 0.0, 'prec_micro': nan, 'rec_micro': 0.0, 'f1_micro': nan, 'rec_at_3': 0.2727272727272727, 'prec_at_3': 0.09090909090909091, 'f1_at_3': 0.13636363636363635, 'auc_macro': 0.5, 'auc_micro': 0.5}\n",
            "\n",
            "Epoch: [7 | 25] LR: 0.001000\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "104it [01:13,  1.39it/s]"
          ]
        }
      ],
      "source": [
        "import warnings\n",
        "warnings.filterwarnings('ignore')\n",
        "# Model\n",
        "print(\"==> creating model ResNet{}\".format(args.depth))\n",
        "import model\n",
        "num_classes = 6\n",
        "\n",
        "model = model.__dict__['resnet_lstm_mitbih'](\n",
        "            num_classes=num_classes,\n",
        "            depth=args.depth,\n",
        "            block_name=args.block_name,\n",
        "        )\n",
        "\n",
        "model = model.cuda()\n",
        "cudnn.benchmark = True\n",
        "print('    Total params: %.2fM' % (sum(p.numel() for p in model.parameters())/1000000.0))\n",
        "criterion = nn.CrossEntropyLoss()\n",
        "# optimizer = optim.SGD(model.parameters(), lr=args.lr, momentum=args.momentum, weight_decay=args.weight_decay)\n",
        "optimizer = optim.Adam(model.parameters(), lr=args.lr, weight_decay=args.weight_decay)\n",
        "\n",
        "# Resume\n",
        "title = 'ecg-lstm-resnet' + str(args.depth)\n",
        "if args.resume:\n",
        "    # Load checkpoint.\n",
        "    print('==> Resuming from checkpoint..')\n",
        "    assert os.path.isfile(args.resume), 'Error: no checkpoint directory found!'\n",
        "    args.checkpoint = os.path.dirname(args.resume)\n",
        "    checkpoint = torch.load(args.resume)\n",
        "    best_acc = checkpoint['best_acc']\n",
        "    start_epoch = checkpoint['epoch']\n",
        "    model.load_state_dict(checkpoint['state_dict'])\n",
        "    optimizer.load_state_dict(checkpoint['optimizer'])\n",
        "    logger = Logger(os.path.join(args.checkpoint, 'log.txt'), title=title, resume=True)\n",
        "else:\n",
        "    logger = Logger(os.path.join(args.checkpoint, 'log.txt'), title=title)\n",
        "    logger.set_names(['Learning Rate', 'Train Loss', 'Valid Loss', 'Train Acc.', 'Valid Acc.'])\n",
        "\n",
        "if args.evaluate:\n",
        "    print('\\nEvaluation only')\n",
        "    test_loss, test_acc= test(testloader, model, criterion, start_epoch, use_cuda, label_names=label_names)\n",
        "    print(' Test Loss:  %.8f, Test Acc:  %.2f' % (test_loss, test_acc))\n",
        "\n",
        "\n",
        "# Train and val\n",
        "for epoch in range(start_epoch, args.epochs):\n",
        "    adjust_learning_rate(optimizer, epoch)\n",
        "    print('\\nEpoch: [%d | %d] LR: %f' % (epoch + 1, args.epochs, state['lr']))\n",
        "    train_loss, train_acc = train(trainloader, model, criterion, optimizer, epoch, use_cuda)\n",
        "    test_loss, test_acc = test(testloader, model, criterion, epoch, use_cuda, label_names=label_names)\n",
        "\n",
        "    print(\"Train accuracy \", train_acc)\n",
        "    print(\"test accuracy \", test_acc)\n",
        "\n",
        "    # append logger file\n",
        "    logger.append([state['lr'], train_loss, test_loss, train_acc['acc_micro'], test_acc['acc_micro']])\n",
        "\n",
        "    # save model\n",
        "    is_best = test_acc['acc_micro'] > best_acc\n",
        "    best_acc = max(test_acc['acc_micro'], best_acc)\n",
        "    save_checkpoint({\n",
        "            'epoch': epoch + 1,\n",
        "            'state_dict': model.state_dict(),\n",
        "            'acc': test_acc['acc_micro'],\n",
        "            'best_acc': best_acc,\n",
        "            'optimizer': optimizer.state_dict(),\n",
        "        }, is_best, checkpoint=args.checkpoint)\n",
        "\n",
        "logger.close()\n",
        "logger.plot()\n",
        "savefig(os.path.join(args.checkpoint, 'log.eps'))\n",
        "\n",
        "print('Best acc:')\n",
        "print(best_acc)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 163,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "S62C4ZXbhAFC",
        "outputId": "ab52cb78-7007-4403-d81a-17f3b5438133"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "6591"
            ]
          },
          "execution_count": 163,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "import gc\n",
        "torch.cuda.empty_cache()\n",
        "gc.collect()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "yMPbAYUSz9hL",
        "outputId": "dc756498-a3ea-446c-8d85-dd3ab53215e3"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "array([[False, False, False, False, False, False],\n",
              "       [False, False, False, False, False,  True]])"
            ]
          },
          "execution_count": 10,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "yhat =  (x > 0.5)\n",
        "yhat"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "O_A-8tZh0oLD",
        "outputId": "399a3c7d-4bc6-4e0a-a988-68228cd824aa"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "{'acc_macro': 0.16666666665,\n",
              " 'prec_macro': 0.16666666665,\n",
              " 'rec_macro': 0.16666666665,\n",
              " 'f1_macro': 0.16666666665,\n",
              " 'acc_micro': 0.5,\n",
              " 'prec_micro': 1.0,\n",
              " 'rec_micro': 0.5,\n",
              " 'f1_micro': 0.6666666666666666,\n",
              " 'rec_at_5': 1.0,\n",
              " 'prec_at_5': 0.2,\n",
              " 'f1_at_5': 0.33333333333333337,\n",
              " 'auc_macro': 0.75,\n",
              " 'auc_micro': 0.925}"
            ]
          },
          "execution_count": 8,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "x = np.array([[ 0.4306,  0.1597, -0.0818, -0.1469,  0.2693, -0.0962],[ 0.4306,  0.1597, -0.0818, -0.1469,  0.4693, 0.5534]])\n",
        "        \n",
        "y = np.array([[1., 0., 0., 0., 0., 0.],[0., 0., 0., 0., 0., 1.]])\n",
        "yhat =  (x > 0.5)\n",
        "all_metrics(yhat, y, k=5, yhat_raw=x, calc_auc=True)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "jvuxkdHS1pOr"
      },
      "outputs": [],
      "source": [
        "|"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "provenance": []
    },
    "gpuClass": "standard",
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "name": "python",
      "version": "3.9.13"
    },
    "vscode": {
      "interpreter": {
        "hash": "67b0c589fb9ccdfebbb6af30a0734e1950a337ecdffd0c382972eb243f65ba5b"
      }
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
