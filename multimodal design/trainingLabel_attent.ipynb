{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from __future__ import print_function\n",
    "\n",
    "import os\n",
    "import cv2\n",
    "import json\n",
    "import time\n",
    "import torch\n",
    "import random\n",
    "import shutil\n",
    "import argparse\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import torch.nn as nn\n",
    "import torch.nn.parallel\n",
    "import torch.optim as optim\n",
    "import sklearn.metrics as skm\n",
    "import torch.utils.data as data\n",
    "import torch.backends.cudnn as cudnn\n",
    "import matplotlib.pyplot as plt\n",
    "from tqdm import tqdm\n",
    "from sklearn.metrics import roc_curve, auc\n",
    "from matplotlib.backends.backend_agg import FigureCanvasAgg as FigureCanvas\n",
    "from matplotlib.figure import Figure\n",
    "# import models as models\n",
    "from utils import Logger, AverageMeter, accuracy, mkdir_p, savefig"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "best_acc = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "parser = argparse.ArgumentParser(description='PyTorch ECG LSTM MITBIH Training')\n",
    "# Datasets\n",
    "parser.add_argument('-dt', '--dataset', default='ecg', type=str)\n",
    "parser.add_argument('-ft', '--transformation', default='stft', type=str)\n",
    "parser.add_argument('-d', '--data', default='generate_features_2/mitbih_rl', type=str)\n",
    "parser.add_argument('-j', '--workers', default=4, type=int, metavar='N',\n",
    "                    help='number of data loading workers (default: 4)')\n",
    "# Optimization options\n",
    "parser.add_argument('--epochs', default=300, type=int, metavar='N',\n",
    "                    help='number of total epochs to run')\n",
    "parser.add_argument('--start-epoch', default=0, type=int, metavar='N',\n",
    "                    help='manual epoch number (useful on restarts)')\n",
    "parser.add_argument('--train-batch', default=64, type=int, metavar='N',\n",
    "                    help='train batchsize')\n",
    "parser.add_argument('--test-batch', default=64, type=int, metavar='N',\n",
    "                    help='test batchsize')\n",
    "parser.add_argument('--lr', '--learning-rate', default=0.001, type=float,\n",
    "                    metavar='LR', help='initial learning rate')\n",
    "parser.add_argument('--drop', '--dropout', default=0, type=float,\n",
    "                    metavar='Dropout', help='Dropout ratio')\n",
    "parser.add_argument('--schedule', type=int, nargs='+', default=[150, 225],\n",
    "                        help='Decrease learning rate at these epochs.')\n",
    "parser.add_argument('--gamma', type=float, default=0.1, help='LR is multiplied by gamma on schedule.')\n",
    "parser.add_argument('--momentum', default=0.9, type=float, metavar='M',\n",
    "                    help='momentum')\n",
    "parser.add_argument('--weight-decay', '--wd', default=5e-4, type=float,\n",
    "                    metavar='W', help='weight decay (default: 1e-4)')\n",
    "# Checkpoints\n",
    "parser.add_argument('-c', '--checkpoint', default='checkpoint', type=str, metavar='PATH',\n",
    "                    help='path to save checkpoint (default: checkpoint)')\n",
    "\n",
    "parser.add_argument('--resume', default='', type=str, metavar='PATH',\n",
    "                    help='path to latest checkpoint (default: none)')\n",
    "\n",
    "# Architecture\n",
    "parser.add_argument('--depth', type=int, default=110, help='Model depth.')\n",
    "parser.add_argument('--block-name', type=str, default='BasicBlock',\n",
    "                    help='the building block for Resnet and Preresnet: BasicBlock, Bottleneck (default: '\n",
    "                         'Basicblock for ecg)')\n",
    "parser.add_argument('--cardinality', type=int, default=8, help='Model cardinality (group).')\n",
    "parser.add_argument('--widen-factor', type=int, default=4, help='Widen factor. 4 -> 64, 8 -> 128, ...')\n",
    "parser.add_argument('--growthRate', type=int, default=12, help='Growth rate for DenseNet.')\n",
    "parser.add_argument('--compressionRate', type=int, default=2, help='Compression Rate (theta) for DenseNet.')\n",
    "# Miscs\n",
    "parser.add_argument('--manualSeed', type=int, help='manual seed')\n",
    "parser.add_argument('-e', '--evaluate', dest='evaluate', action='store_true', default=False,\n",
    "                    help='evaluate model on validation set')\n",
    "# Device options\n",
    "parser.add_argument('--gpu-id', default='1', type=str,\n",
    "                    help='id(s) for CUDA_VISIBLE_DEVICES')\n",
    "\n",
    "args = parser.parse_args(\"\")\n",
    "state = {k: v for k, v in args._get_kwargs()}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'dataset': 'ecg',\n",
       " 'transformation': 'stft',\n",
       " 'data': 'generate_features_2/mitbih_rl',\n",
       " 'workers': 4,\n",
       " 'epochs': 300,\n",
       " 'start_epoch': 0,\n",
       " 'train_batch': 64,\n",
       " 'test_batch': 64,\n",
       " 'lr': 0.001,\n",
       " 'drop': 0,\n",
       " 'schedule': [150, 225],\n",
       " 'gamma': 0.1,\n",
       " 'momentum': 0.9,\n",
       " 'weight_decay': 0.0005,\n",
       " 'checkpoint': 'checkpoint',\n",
       " 'resume': '',\n",
       " 'depth': 110,\n",
       " 'block_name': 'BasicBlock',\n",
       " 'cardinality': 8,\n",
       " 'widen_factor': 4,\n",
       " 'growthRate': 12,\n",
       " 'compressionRate': 2,\n",
       " 'manualSeed': None,\n",
       " 'evaluate': False,\n",
       " 'gpu_id': '1'}"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "state"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<torch._C.Generator at 0x2963e474090>"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "if args.manualSeed is None:\n",
    "    args.manualSeed = random.randint(1, 10000)\n",
    "random.seed(args.manualSeed)\n",
    "torch.manual_seed(args.manualSeed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Ecg_loader(torch.utils.data.Dataset):\n",
    "    def __init__(self, path, transform):\n",
    "        super(Ecg_loader, self).__init__()\n",
    "        self.male_vec = np.load('male_vec.npy')\n",
    "        self.female_vec = np.load('female_vec.npy')\n",
    "\n",
    "        with open(os.path.join(path, 'ecg_labels.json')) as j_file:\n",
    "            json_data = json.load(j_file)\n",
    "        self.idx2name = json_data['labels']\n",
    "        data = json_data['data']\n",
    "        self.inputs = []\n",
    "        self.labels = []\n",
    "        self.gender = []\n",
    "        self.inputs_full = []\n",
    "        self.whole_ecg = []\n",
    "        self.ecg = []\n",
    "        self.age = []\n",
    "        for i in tqdm(data):\n",
    "            subject_img = []\n",
    "            subject_ecg = []\n",
    "            a = np.zeros((100))\n",
    "            for i_name, w_name in zip(i['images'], i['ecg']):\n",
    "                print(os.path.join(path, 'images', transform, i_name))\n",
    "                img = cv2.imread(os.path.join(path, 'images', transform, i_name))\n",
    "                print(img)\n",
    "                img = cv2.cvtColor(img, cv2.COLOR_BGR2RGB)\n",
    "                img = cv2.resize(img, (90, 90))\n",
    "                ecg = np.load(os.path.join(path, 'ecg', w_name))\n",
    "                subject_img.append(np.expand_dims(img.transpose((2, 0, 1)), axis=0))\n",
    "                subject_ecg.append(np.expand_dims(np.expand_dims(ecg, axis=0), axis=0))\n",
    "            img_full = cv2.imread(os.path.join(path, 'images_full', transform, i['images_full']))\n",
    "            img_full = cv2.cvtColor(img_full, cv2.COLOR_BGR2RGB)\n",
    "            l = i['label']\n",
    "            a[int(i['age']*100)] = 1\n",
    "            if i['gender'] == [0, 1]:\n",
    "                g = self.male_vec\n",
    "            elif i['gender'] == [1, 0]:\n",
    "                g = self.female_vec\n",
    "            self.inputs_full.append(img_full.transpose((2, 0, 1)))\n",
    "            self.inputs.append(np.concatenate(subject_img, axis=0))\n",
    "            self.ecg.append(np.concatenate(subject_ecg, axis=0))\n",
    "            self.whole_ecg.append(np.concatenate(subject_ecg, axis=2))\n",
    "            self.labels.append(np.array(l))\n",
    "            self.gender.append(g)\n",
    "            self.age.append(a)\n",
    "        print(len(self.whole_ecg))\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.labels)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        x = torch.from_numpy(self.inputs[idx]).float()\n",
    "        y = torch.from_numpy(np.array(self.labels[idx])).long()\n",
    "        a = torch.from_numpy(np.array(self.age[idx])).float()\n",
    "        g = torch.from_numpy(np.array(self.gender[idx])).float()\n",
    "        w = torch.from_numpy(self.ecg[idx]).float()\n",
    "        return (x, a, g, w), y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate(outputs, labels, label_names=None):\n",
    "    gt = torch.cat(labels, dim=0)\n",
    "    pred = torch.cat(outputs, dim=0)\n",
    "    probs = pred\n",
    "    pred = torch.argmax(pred, dim=1)\n",
    "    acc = torch.div(100*torch.sum((gt == pred).float()), gt.shape[0])\n",
    "    name_dict = {0: 'Normal beat (N)', 1: 'Left bundle branch block beat (L)', 2: 'Right bundle branch block beat (R)', 3:\n",
    "        'Premature ventricular contraction (V)', 4: 'Atrial premature beat (A)', 5: 'Non classified (~)'}\n",
    "\n",
    "    print('accuracy :', acc)\n",
    "\n",
    "    gt = gt.cpu().tolist()\n",
    "    pred = pred.cpu().tolist()\n",
    "\n",
    "    report = skm.classification_report(\n",
    "        gt, pred,\n",
    "        target_names=[name_dict[i] for i in np.unique(gt)],\n",
    "        digits=3)\n",
    "    scores = skm.precision_recall_fscore_support(\n",
    "        gt,\n",
    "        pred,\n",
    "        average=None)\n",
    "    print(report)\n",
    "    print(\"F1 Average {:3f}\".format(np.mean(scores[2][:3])))\n",
    "\n",
    "    fpr = dict()\n",
    "    tpr = dict()\n",
    "    roc_auc = dict()\n",
    "    n_classes = np.unique(gt).shape[0]\n",
    "    oh_gt = np.zeros((len(gt), n_classes))\n",
    "    plt.figure()\n",
    "    colors = ['b', 'g', 'r', 'c', 'm', 'y']\n",
    "\n",
    "    for i in range(n_classes):\n",
    "        oh_gt[:, gt == i] = 1\n",
    "        fpr[i], tpr[i], _ = roc_curve(gt, probs[:, i].cpu(), pos_label=i)\n",
    "        roc_auc[i] = auc(fpr[i], tpr[i])\n",
    "        lw = 2\n",
    "        plt.plot(fpr[i], tpr[i], color=colors[i],\n",
    "                 lw=lw, label=name_dict[i] +' : %0.4f' % roc_auc[i])\n",
    "    plt.xlim([0.0, 1.0])\n",
    "    plt.ylim([0.0, 1.05])\n",
    "    plt.xlabel('False Positive Rate')\n",
    "    plt.ylabel('True Positive Rate')\n",
    "    plt.title('Class-Wise AUC and ROC curve')\n",
    "    plt.legend(loc=\"lower right\")\n",
    "    plt.savefig(os.path.join(args.checkpoint, 'roc.png'))\n",
    "    return 0\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train(trainloader, model, criterion, optimizer, epoch, use_cuda):\n",
    "    # switch to train mode\n",
    "    model.train()\n",
    "\n",
    "    batch_time = AverageMeter()\n",
    "    data_time = AverageMeter()\n",
    "    losses = AverageMeter()\n",
    "    top1 = AverageMeter()\n",
    "    top5 = AverageMeter()\n",
    "    end = time.time()\n",
    "\n",
    "\n",
    "    for batch_idx, (inputs, targets) in tqdm(enumerate(trainloader)):\n",
    "        # measure data loading time\n",
    "        data_time.update(time.time() - end)\n",
    "\n",
    "        if use_cuda:\n",
    "            inputs, targets = (inputs[0].cuda(), inputs[1].cuda(), inputs[2].cuda(),\n",
    "                               inputs[3].cuda()), targets.cuda()\n",
    "        inputs, targets = (torch.autograd.Variable(inputs[0]), torch.autograd.Variable(inputs[1]),\n",
    "                           torch.autograd.Variable(inputs[2]),\n",
    "                           torch.autograd.Variable(inputs[3])), torch.autograd.Variable(targets)\n",
    "\n",
    "        outputs = model(inputs)\n",
    "        loss = criterion(outputs, targets)\n",
    "\n",
    "        prec1, prec5 = accuracy(outputs.data, targets.data, topk=(1, 6))\n",
    "\n",
    "        if float(torch.__version__[:3]) < 0.5:\n",
    "            losses.update(loss.data[0], inputs[0].size(0))\n",
    "            top1.update(prec1[0], inputs[0].size(0))\n",
    "            top5.update(prec5[0], inputs[0].size(0))\n",
    "        else:\n",
    "            losses.update(loss.data, inputs[0].size(0))\n",
    "            top1.update(prec1, inputs[0].size(0))\n",
    "            top5.update(prec5, inputs[0].size(0))\n",
    "\n",
    "        # compute gradient and do Adam step\n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        # measure elapsed time\n",
    "        batch_time.update(time.time() - end)\n",
    "        end = time.time()\n",
    "    # evaluate(pred, gt)\n",
    "    return (losses.avg, top1.avg)\n",
    "\n",
    "\n",
    "def test(testloader, model, criterion, epoch, use_cuda, label_names=None):\n",
    "    global best_acc\n",
    "\n",
    "    batch_time = AverageMeter()\n",
    "    data_time = AverageMeter()\n",
    "    losses = AverageMeter()\n",
    "    top1 = AverageMeter()\n",
    "    top5 = AverageMeter()\n",
    "\n",
    "    # switch to evaluate mode\n",
    "    model.eval()\n",
    "\n",
    "    end = time.time()\n",
    "\n",
    "    gt = []\n",
    "    pred = []\n",
    "    for batch_idx, (inputs, targets) in tqdm(enumerate(testloader)):\n",
    "        # measure data loading time\n",
    "        data_time.update(time.time() - end)\n",
    "\n",
    "        if use_cuda:\n",
    "            inputs, targets = (inputs[0].cuda(), inputs[1].cuda(), inputs[2].cuda(),\n",
    "                               inputs[3].cuda()), targets.cuda()\n",
    "        inputs, targets = (torch.autograd.Variable(inputs[0]), torch.autograd.Variable(inputs[1]),\n",
    "                           torch.autograd.Variable(inputs[2]),\n",
    "                           torch.autograd.Variable(inputs[3])), torch.autograd.Variable(targets)\n",
    "\n",
    "        # compute output\n",
    "        st = time.time()\n",
    "        outputs = model(inputs)\n",
    "        # print(time.time()-st)\n",
    "        loss = criterion(outputs, targets)\n",
    "        # measure accuracy and record loss\n",
    "        gt.append(targets.data)\n",
    "        pred.append(outputs.data)\n",
    "        prec1, prec5 = accuracy(outputs.data, targets.data, topk=(1, 6))\n",
    "        if float(torch.__version__[:3]) < 0.5:\n",
    "            losses.update(loss.data[0], inputs[0].size(0))\n",
    "            top1.update(prec1[0], inputs[0].size(0))\n",
    "            top5.update(prec5[0], inputs[0].size(0))\n",
    "        else:\n",
    "            losses.update(loss.data, inputs[0].size(0))\n",
    "            top1.update(prec1, inputs[0].size(0))\n",
    "            top5.update(prec5, inputs[0].size(0))\n",
    "\n",
    "        # measure elapsed time\n",
    "        batch_time.update(time.time() - end)\n",
    "        end = time.time()\n",
    "    evaluate(pred, gt, label_names=label_names)\n",
    "    return (losses.avg, top1.avg)\n",
    "\n",
    "\n",
    "def save_checkpoint(state, is_best, checkpoint='checkpoint', filename='checkpoint.pth.tar'):\n",
    "    filepath = os.path.join(checkpoint, filename)\n",
    "    torch.save(state, filepath)\n",
    "    if is_best:\n",
    "        shutil.copyfile(filepath, os.path.join(checkpoint, 'model_best.pth.tar'))\n",
    "\n",
    "\n",
    "def adjust_learning_rate(optimizer, epoch):\n",
    "    global state\n",
    "    if epoch in args.schedule:\n",
    "        state['lr'] *= args.gamma\n",
    "        for param_group in optimizer.param_groups:\n",
    "            param_group['lr'] = state['lr']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "==> Preparing dataset ecg\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 1/396 [00:00<00:07, 52.77it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "generate_features_2/mitbih_rl\\val\\images\\stft\\0_0.jpg\n",
      "[[[142 120  42]\n",
      "  [142 120  42]\n",
      "  [142 120  42]\n",
      "  ...\n",
      "  [137 145  31]\n",
      "  [138 146  32]\n",
      "  [138 146  32]]\n",
      "\n",
      " [[142 120  42]\n",
      "  [142 120  42]\n",
      "  [142 120  42]\n",
      "  ...\n",
      "  [137 145  31]\n",
      "  [138 146  32]\n",
      "  [138 146  32]]\n",
      "\n",
      " [[141 119  41]\n",
      "  [141 119  41]\n",
      "  [141 119  41]\n",
      "  ...\n",
      "  [138 146  32]\n",
      "  [138 146  32]\n",
      "  [138 146  32]]\n",
      "\n",
      " ...\n",
      "\n",
      " [[ 86 201 104]\n",
      "  [ 86 202 105]\n",
      "  [ 87 203 108]\n",
      "  ...\n",
      "  [ 34 226 196]\n",
      "  [ 34 226 196]\n",
      "  [ 34 226 196]]\n",
      "\n",
      " [[ 86 202 107]\n",
      "  [ 87 203 108]\n",
      "  [ 86 203 110]\n",
      "  ...\n",
      "  [ 33 226 199]\n",
      "  [ 32 225 198]\n",
      "  [ 32 225 198]]\n",
      "\n",
      " [[ 88 204 109]\n",
      "  [ 86 204 109]\n",
      "  [ 88 205 112]\n",
      "  ...\n",
      "  [ 33 226 200]\n",
      "  [ 33 226 199]\n",
      "  [ 33 226 199]]]\n",
      "generate_features_2/mitbih_rl\\val\\images\\stft\\0_1.jpg\n",
      "[[[144 123  41]\n",
      "  [143 122  40]\n",
      "  [142 120  42]\n",
      "  ...\n",
      "  [140 115  43]\n",
      "  [140 116  44]\n",
      "  [142 119  44]]\n",
      "\n",
      " [[144 123  41]\n",
      "  [143 122  41]\n",
      "  [141 119  41]\n",
      "  ...\n",
      "  [141 116  44]\n",
      "  [142 118  46]\n",
      "  [143 120  45]]\n",
      "\n",
      " [[144 123  41]\n",
      "  [143 122  41]\n",
      "  [141 119  41]\n",
      "  ...\n",
      "  [142 117  45]\n",
      "  [143 119  47]\n",
      "  [144 121  46]]\n",
      "\n",
      " ...\n",
      "\n",
      " [[118 176  67]\n",
      "  [117 178  68]\n",
      "  [115 179  73]\n",
      "  ...\n",
      "  [ 48 220 172]\n",
      "  [ 50 220 172]\n",
      "  [ 50 220 171]]\n",
      "\n",
      " [[119 168  58]\n",
      "  [119 170  59]\n",
      "  [118 172  65]\n",
      "  ...\n",
      "  [ 47 221 174]\n",
      "  [ 49 220 174]\n",
      "  [ 49 221 173]]\n",
      "\n",
      " [[120 163  52]\n",
      "  [120 165  55]\n",
      "  [119 169  61]\n",
      "  ...\n",
      "  [ 48 221 177]\n",
      "  [ 50 221 175]\n",
      "  [ 50 221 175]]]\n",
      "generate_features_2/mitbih_rl\\val\\images\\stft\\0_2.jpg\n",
      "[[[135 166  35]\n",
      "  [135 166  35]\n",
      "  [134 164  35]\n",
      "  ...\n",
      "  [131 140  30]\n",
      "  [133 145  33]\n",
      "  [136 149  34]]\n",
      "\n",
      " [[135 166  35]\n",
      "  [135 166  35]\n",
      "  [134 164  35]\n",
      "  ...\n",
      "  [133 144  34]\n",
      "  [137 149  37]\n",
      "  [140 153  38]]\n",
      "\n",
      " [[135 166  35]\n",
      "  [135 166  35]\n",
      "  [134 164  35]\n",
      "  ...\n",
      "  [135 147  35]\n",
      "  [139 152  37]\n",
      "  [139 155  38]]\n",
      "\n",
      " ...\n",
      "\n",
      " [[ 30 224 201]\n",
      "  [ 28 224 201]\n",
      "  [ 29 225 203]\n",
      "  ...\n",
      "  [ 44 219 181]\n",
      "  [ 46 220 180]\n",
      "  [ 46 220 180]]\n",
      "\n",
      " [[ 29 225 203]\n",
      "  [ 29 225 203]\n",
      "  [ 30 225 205]\n",
      "  ...\n",
      "  [ 45 222 183]\n",
      "  [ 45 221 181]\n",
      "  [ 45 221 181]]\n",
      "\n",
      " [[ 30 226 204]\n",
      "  [ 30 226 204]\n",
      "  [ 30 226 206]\n",
      "  ...\n",
      "  [ 46 223 184]\n",
      "  [ 46 222 182]\n",
      "  [ 46 222 182]]]\n",
      "generate_features_2/mitbih_rl\\val\\images\\stft\\0_3.jpg\n",
      "[[[144 128  39]\n",
      "  [144 128  39]\n",
      "  [143 126  39]\n",
      "  ...\n",
      "  [139 141  35]\n",
      "  [140 143  34]\n",
      "  [140 143  34]]\n",
      "\n",
      " [[144 128  39]\n",
      "  [144 128  39]\n",
      "  [143 126  39]\n",
      "  ...\n",
      "  [139 141  35]\n",
      "  [140 143  34]\n",
      "  [140 143  34]]\n",
      "\n",
      " [[144 128  39]\n",
      "  [144 128  39]\n",
      "  [143 126  39]\n",
      "  ...\n",
      "  [139 141  35]\n",
      "  [139 142  33]\n",
      "  [140 143  34]]\n",
      "\n",
      " ...\n",
      "\n",
      " [[ 52 215 170]\n",
      "  [ 50 215 170]\n",
      "  [ 51 216 171]\n",
      "  ...\n",
      "  [ 41 220 181]\n",
      "  [ 42 219 180]\n",
      "  [ 40 219 180]]\n",
      "\n",
      " [[ 52 217 174]\n",
      "  [ 50 217 174]\n",
      "  [ 51 218 175]\n",
      "  ...\n",
      "  [ 41 222 184]\n",
      "  [ 42 220 183]\n",
      "  [ 40 221 183]]\n",
      "\n",
      " [[ 52 219 176]\n",
      "  [ 52 219 176]\n",
      "  [ 52 219 178]\n",
      "  ...\n",
      "  [ 43 223 188]\n",
      "  [ 42 223 185]\n",
      "  [ 42 223 185]]]\n",
      "generate_features_2/mitbih_rl\\val\\images\\stft\\0_4.jpg\n",
      "[[[139 150  34]\n",
      "  [139 150  34]\n",
      "  [140 148  34]\n",
      "  ...\n",
      "  [136 142  31]\n",
      "  [137 143  32]\n",
      "  [137 143  32]]\n",
      "\n",
      " [[139 150  34]\n",
      "  [139 150  34]\n",
      "  [140 148  34]\n",
      "  ...\n",
      "  [137 143  32]\n",
      "  [137 143  32]\n",
      "  [137 143  32]]\n",
      "\n",
      " [[140 152  34]\n",
      "  [139 151  33]\n",
      "  [138 149  33]\n",
      "  ...\n",
      "  [138 143  34]\n",
      "  [138 144  33]\n",
      "  [138 144  33]]\n",
      "\n",
      " ...\n",
      "\n",
      " [[ 34 222 197]\n",
      "  [ 32 222 197]\n",
      "  [ 35 223 198]\n",
      "  ...\n",
      "  [ 44 220 173]\n",
      "  [ 44 219 175]\n",
      "  [ 44 220 173]]\n",
      "\n",
      " [[ 32 221 199]\n",
      "  [ 30 222 199]\n",
      "  [ 33 222 200]\n",
      "  ...\n",
      "  [ 43 221 176]\n",
      "  [ 43 220 177]\n",
      "  [ 43 221 176]]\n",
      "\n",
      " [[ 30 222 199]\n",
      "  [ 31 223 200]\n",
      "  [ 32 223 202]\n",
      "  ...\n",
      "  [ 44 221 178]\n",
      "  [ 44 221 178]\n",
      "  [ 44 221 178]]]\n",
      "generate_features_2/mitbih_rl\\val\\images\\stft\\0_5.jpg\n",
      "[[[143 121  43]\n",
      "  [143 121  43]\n",
      "  [143 118  44]\n",
      "  ...\n",
      "  [140 143  34]\n",
      "  [140 143  34]\n",
      "  [140 143  34]]\n",
      "\n",
      " [[143 121  43]\n",
      "  [143 121  43]\n",
      "  [143 119  43]\n",
      "  ...\n",
      "  [139 142  33]\n",
      "  [140 143  34]\n",
      "  [140 143  34]]\n",
      "\n",
      " [[144 122  44]\n",
      "  [143 121  43]\n",
      "  [143 119  43]\n",
      "  ...\n",
      "  [141 141  35]\n",
      "  [139 141  35]\n",
      "  [140 142  36]]\n",
      "\n",
      " ...\n",
      "\n",
      " [[ 43 220 171]\n",
      "  [ 44 221 172]\n",
      "  [ 44 220 173]\n",
      "  ...\n",
      "  [ 37 225 200]\n",
      "  [ 36 224 199]\n",
      "  [ 36 225 198]]\n",
      "\n",
      " [[ 45 220 170]\n",
      "  [ 43 220 170]\n",
      "  [ 44 221 172]\n",
      "  ...\n",
      "  [ 38 224 200]\n",
      "  [ 37 223 199]\n",
      "  [ 37 223 199]]\n",
      "\n",
      " [[ 45 220 170]\n",
      "  [ 46 221 171]\n",
      "  [ 44 221 172]\n",
      "  ...\n",
      "  [ 39 225 203]\n",
      "  [ 38 224 200]\n",
      "  [ 37 223 199]]]\n",
      "generate_features_2/mitbih_rl\\val\\images\\stft\\0_6.jpg\n",
      "[[[140 147  32]\n",
      "  [140 147  32]\n",
      "  [139 145  32]\n",
      "  ...\n",
      "  [138 152  34]\n",
      "  [137 154  33]\n",
      "  [137 154  33]]\n",
      "\n",
      " [[140 147  32]\n",
      "  [140 147  32]\n",
      "  [139 145  32]\n",
      "  ...\n",
      "  [138 152  34]\n",
      "  [137 154  33]\n",
      "  [137 154  33]]\n",
      "\n",
      " [[140 147  32]\n",
      "  [139 146  31]\n",
      "  [139 145  32]\n",
      "  ...\n",
      "  [137 151  33]\n",
      "  [136 153  32]\n",
      "  [137 154  33]]\n",
      "\n",
      " ...\n",
      "\n",
      " [[ 55 215 161]\n",
      "  [ 53 216 161]\n",
      "  [ 54 217 162]\n",
      "  ...\n",
      "  [ 26 227 218]\n",
      "  [ 26 227 218]\n",
      "  [ 25 226 217]]\n",
      "\n",
      " [[ 53 215 163]\n",
      "  [ 53 215 163]\n",
      "  [ 54 216 164]\n",
      "  ...\n",
      "  [ 25 227 220]\n",
      "  [ 25 227 220]\n",
      "  [ 24 226 219]]\n",
      "\n",
      " [[ 53 215 163]\n",
      "  [ 54 216 164]\n",
      "  [ 54 217 166]\n",
      "  ...\n",
      "  [ 26 228 221]\n",
      "  [ 26 228 221]\n",
      "  [ 26 228 221]]]\n",
      "generate_features_2/mitbih_rl\\val\\images\\stft\\0_7.jpg\n",
      "[[[139 144  35]\n",
      "  [139 144  35]\n",
      "  [138 142  36]\n",
      "  ...\n",
      "  [142 133  36]\n",
      "  [143 134  36]\n",
      "  [143 134  36]]\n",
      "\n",
      " [[139 144  35]\n",
      "  [139 144  35]\n",
      "  [138 142  36]\n",
      "  ...\n",
      "  [142 133  36]\n",
      "  [143 134  36]\n",
      "  [144 135  37]]\n",
      "\n",
      " [[140 146  35]\n",
      "  [139 145  34]\n",
      "  [138 143  34]\n",
      "  ...\n",
      "  [143 134  37]\n",
      "  [144 135  37]\n",
      "  [144 135  37]]\n",
      "\n",
      " ...\n",
      "\n",
      " [[ 44 219 181]\n",
      "  [ 43 220 181]\n",
      "  [ 44 221 182]\n",
      "  ...\n",
      "  [ 48 218 169]\n",
      "  [ 49 218 169]\n",
      "  [ 49 219 167]]\n",
      "\n",
      " [[ 43 219 182]\n",
      "  [ 43 219 182]\n",
      "  [ 44 220 183]\n",
      "  ...\n",
      "  [ 48 221 171]\n",
      "  [ 49 219 170]\n",
      "  [ 49 219 170]]\n",
      "\n",
      " [[ 43 219 182]\n",
      "  [ 44 220 183]\n",
      "  [ 43 221 186]\n",
      "  ...\n",
      "  [ 50 222 174]\n",
      "  [ 51 221 172]\n",
      "  [ 50 220 171]]]\n",
      "generate_features_2/mitbih_rl\\val\\images\\stft\\0_8.jpg\n",
      "[[[140 118  40]\n",
      "  [140 118  40]\n",
      "  [139 114  40]\n",
      "  ...\n",
      "  [138 112  45]\n",
      "  [139 114  44]\n",
      "  [139 114  44]]\n",
      "\n",
      " [[142 120  42]\n",
      "  [141 119  41]\n",
      "  [141 116  42]\n",
      "  ...\n",
      "  [139 113  46]\n",
      "  [139 114  44]\n",
      "  [139 114  44]]\n",
      "\n",
      " [[143 121  43]\n",
      "  [142 120  42]\n",
      "  [142 117  43]\n",
      "  ...\n",
      "  [140 114  47]\n",
      "  [140 115  45]\n",
      "  [140 115  45]]\n",
      "\n",
      " ...\n",
      "\n",
      " [[ 52 216 168]\n",
      "  [ 50 217 168]\n",
      "  [ 51 217 170]\n",
      "  ...\n",
      "  [ 69 211 136]\n",
      "  [ 69 211 134]\n",
      "  [ 70 210 133]]\n",
      "\n",
      " [[ 52 218 171]\n",
      "  [ 52 218 171]\n",
      "  [ 53 218 173]\n",
      "  ...\n",
      "  [ 69 212 139]\n",
      "  [ 70 211 138]\n",
      "  [ 70 212 137]]\n",
      "\n",
      " [[ 54 220 173]\n",
      "  [ 54 220 173]\n",
      "  [ 53 221 175]\n",
      "  ...\n",
      "  [ 70 214 142]\n",
      "  [ 72 213 140]\n",
      "  [ 71 212 139]]]\n",
      "generate_features_2/mitbih_rl\\val\\images\\stft\\0_9.jpg\n",
      "[[[142 114  43]\n",
      "  [143 115  44]\n",
      "  [143 115  44]\n",
      "  ...\n",
      "  [135 148  32]\n",
      "  [134 150  33]\n",
      "  [135 151  33]]\n",
      "\n",
      " [[142 115  41]\n",
      "  [142 115  41]\n",
      "  [143 116  42]\n",
      "  ...\n",
      "  [137 150  34]\n",
      "  [136 152  35]\n",
      "  [136 152  34]]\n",
      "\n",
      " [[141 118  40]\n",
      "  [141 118  40]\n",
      "  [141 118  40]\n",
      "  ...\n",
      "  [138 151  35]\n",
      "  [137 153  36]\n",
      "  [137 153  35]]\n",
      "\n",
      " ...\n",
      "\n",
      " [[ 54 219 162]\n",
      "  [ 54 219 162]\n",
      "  [ 53 218 161]\n",
      "  ...\n",
      "  [ 30 224 211]\n",
      "  [ 30 224 211]\n",
      "  [ 30 224 211]]\n",
      "\n",
      " [[ 49 220 164]\n",
      "  [ 49 220 164]\n",
      "  [ 48 219 163]\n",
      "  ...\n",
      "  [ 31 225 213]\n",
      "  [ 31 225 213]\n",
      "  [ 31 225 213]]\n",
      "\n",
      " [[ 46 221 164]\n",
      "  [ 46 221 164]\n",
      "  [ 46 221 164]\n",
      "  ...\n",
      "  [ 32 225 215]\n",
      "  [ 32 226 214]\n",
      "  [ 32 226 214]]]\n",
      "generate_features_2/mitbih_rl\\val\\images\\stft\\5_0.jpg\n",
      "None\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "ename": "error",
     "evalue": "OpenCV(4.7.0) D:\\a\\opencv-python\\opencv-python\\opencv\\modules\\imgproc\\src\\color.cpp:182: error: (-215:Assertion failed) !_src.empty() in function 'cv::cvtColor'\n",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31merror\u001b[0m                                     Traceback (most recent call last)",
      "Cell \u001b[1;32mIn [24], line 16\u001b[0m\n\u001b[0;32m     13\u001b[0m valdir \u001b[39m=\u001b[39m os\u001b[39m.\u001b[39mpath\u001b[39m.\u001b[39mjoin(train_path, \u001b[39m'\u001b[39m\u001b[39mval\u001b[39m\u001b[39m'\u001b[39m)\n\u001b[0;32m     14\u001b[0m \u001b[39m# if not args.evaluate:\u001b[39;00m\n\u001b[0;32m     15\u001b[0m \u001b[39m#     trainset = dataloader(traindir, transform=args.transformation)\u001b[39;00m\n\u001b[1;32m---> 16\u001b[0m testset \u001b[39m=\u001b[39m dataloader(valdir, transform\u001b[39m=\u001b[39;49margs\u001b[39m.\u001b[39;49mtransformation)\n",
      "Cell \u001b[1;32mIn [23], line 26\u001b[0m, in \u001b[0;36mEcg_loader.__init__\u001b[1;34m(self, path, transform)\u001b[0m\n\u001b[0;32m     24\u001b[0m img \u001b[39m=\u001b[39m cv2\u001b[39m.\u001b[39mimread(os\u001b[39m.\u001b[39mpath\u001b[39m.\u001b[39mjoin(path, \u001b[39m'\u001b[39m\u001b[39mimages\u001b[39m\u001b[39m'\u001b[39m, transform, i_name))\n\u001b[0;32m     25\u001b[0m \u001b[39mprint\u001b[39m(img)\n\u001b[1;32m---> 26\u001b[0m img \u001b[39m=\u001b[39m cv2\u001b[39m.\u001b[39;49mcvtColor(img, cv2\u001b[39m.\u001b[39;49mCOLOR_BGR2RGB)\n\u001b[0;32m     27\u001b[0m img \u001b[39m=\u001b[39m cv2\u001b[39m.\u001b[39mresize(img, (\u001b[39m90\u001b[39m, \u001b[39m90\u001b[39m))\n\u001b[0;32m     28\u001b[0m ecg \u001b[39m=\u001b[39m np\u001b[39m.\u001b[39mload(os\u001b[39m.\u001b[39mpath\u001b[39m.\u001b[39mjoin(path, \u001b[39m'\u001b[39m\u001b[39mecg\u001b[39m\u001b[39m'\u001b[39m, w_name))\n",
      "\u001b[1;31merror\u001b[0m: OpenCV(4.7.0) D:\\a\\opencv-python\\opencv-python\\opencv\\modules\\imgproc\\src\\color.cpp:182: error: (-215:Assertion failed) !_src.empty() in function 'cv::cvtColor'\n"
     ]
    }
   ],
   "source": [
    "start_epoch = args.start_epoch  # start from epoch 0 or last checkpoint epoch\n",
    "\n",
    "if not os.path.isdir(args.checkpoint):\n",
    "    mkdir_p(args.checkpoint)\n",
    "\n",
    "# Data\n",
    "print('==> Preparing dataset %s' % args.dataset)\n",
    "\n",
    "dataloader = Ecg_loader\n",
    "train_path = args.data\n",
    "\n",
    "traindir = os.path.join(train_path, 'train')\n",
    "valdir = os.path.join(train_path, 'val')\n",
    "if not args.evaluate:\n",
    "    trainset = dataloader(traindir, transform=args.transformation)\n",
    "testset = dataloader(valdir, transform=args.transformation)\n",
    "\n",
    "idx2name = testset.idx2name\n",
    "label_names = []\n",
    "for i in range(0, len(idx2name.keys())):\n",
    "    label_names.append(idx2name[str(i)])\n",
    "num_classes = len(label_names)\n",
    "\n",
    "if not args.evaluate:\n",
    "    trainloader = data.DataLoader(trainset, batch_size=args.train_batch, shuffle=True, num_workers=args.workers)\n",
    "print(\"loading test data\")\n",
    "testloader = data.DataLoader(testset, batch_size=args.test_batch, shuffle=False, num_workers=args.workers)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Model\n",
    "print(\"==> creating model ResNet{}\".format(args.depth))\n",
    "\n",
    "model = models.__dict__['resnet_lstm_mitbih'](\n",
    "            num_classes=num_classes,\n",
    "            depth=args.depth,\n",
    "            block_name=args.block_name,\n",
    "        )\n",
    "\n",
    "model = torch.nn.DataParallel(model).cuda()\n",
    "cudnn.benchmark = True\n",
    "print('    Total params: %.2fM' % (sum(p.numel() for p in model.parameters())/1000000.0))\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "# optimizer = optim.SGD(model.parameters(), lr=args.lr, momentum=args.momentum, weight_decay=args.weight_decay)\n",
    "optimizer = optim.Adam(model.parameters(), lr=args.lr, weight_decay=args.weight_decay)\n",
    "\n",
    "# Resume\n",
    "title = 'ecg-lstm-resnet' + str(args.depth)\n",
    "if args.resume:\n",
    "    # Load checkpoint.\n",
    "    print('==> Resuming from checkpoint..')\n",
    "    assert os.path.isfile(args.resume), 'Error: no checkpoint directory found!'\n",
    "    args.checkpoint = os.path.dirname(args.resume)\n",
    "    checkpoint = torch.load(args.resume)\n",
    "    best_acc = checkpoint['best_acc']\n",
    "    start_epoch = checkpoint['epoch']\n",
    "    model.load_state_dict(checkpoint['state_dict'])\n",
    "    optimizer.load_state_dict(checkpoint['optimizer'])\n",
    "    logger = Logger(os.path.join(args.checkpoint, 'log.txt'), title=title, resume=True)\n",
    "else:\n",
    "    logger = Logger(os.path.join(args.checkpoint, 'log.txt'), title=title)\n",
    "    logger.set_names(['Learning Rate', 'Train Loss', 'Valid Loss', 'Train Acc.', 'Valid Acc.'])\n",
    "\n",
    "if args.evaluate:\n",
    "    print('\\nEvaluation only')\n",
    "    test_loss, test_acc= test(testloader, model, criterion, start_epoch, use_cuda, label_names=label_names)\n",
    "    print(' Test Loss:  %.8f, Test Acc:  %.2f' % (test_loss, test_acc))\n",
    "\n",
    "    return\n",
    "\n",
    "# Train and val\n",
    "for epoch in range(start_epoch, args.epochs):\n",
    "    adjust_learning_rate(optimizer, epoch)\n",
    "\n",
    "    print('\\nEpoch: [%d | %d] LR: %f' % (epoch + 1, args.epochs, state['lr']))\n",
    "\n",
    "    train_loss, train_acc = train(trainloader, model, criterion, optimizer, epoch, use_cuda)\n",
    "    test_loss, test_acc = test(testloader, model, criterion, epoch, use_cuda, label_names=label_names)\n",
    "\n",
    "    # append logger file\n",
    "    logger.append([state['lr'], train_loss, test_loss, train_acc, test_acc])\n",
    "\n",
    "    # save model\n",
    "    is_best = test_acc > best_acc\n",
    "    best_acc = max(test_acc, best_acc)\n",
    "    save_checkpoint({\n",
    "            'epoch': epoch + 1,\n",
    "            'state_dict': model.state_dict(),\n",
    "            'acc': test_acc,\n",
    "            'best_acc': best_acc,\n",
    "            'optimizer': optimizer.state_dict(),\n",
    "        }, is_best, checkpoint=args.checkpoint)\n",
    "\n",
    "logger.close()\n",
    "logger.plot()\n",
    "savefig(os.path.join(args.checkpoint, 'log.eps'))\n",
    "\n",
    "print('Best acc:')\n",
    "print(best_acc)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "67b0c589fb9ccdfebbb6af30a0734e1950a337ecdffd0c382972eb243f65ba5b"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
